{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Gravitas-NLP\\Gravitas-NLP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Gravitas-NLP'...\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/cher-liang/Gravitas-NLP\n",
    "%cd Gravitas-NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git checkout restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!7z x datasets.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Dev\\Gravitas-NLP\\CustomCrossEncoder.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import logging \n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict \n",
    "from datetime import datetime\n",
    "import math\n",
    "\n",
    "from CustomCrossEncoder import CrossEncoder\n",
    "from CustomEvaluator import CECustomEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\", level=logging.INFO, \n",
    ")\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QnliData:\n",
    "    def __init__(self, row) -> None:\n",
    "        self.sentence_pair = (row[\"question\"],row[\"answer\"])\n",
    "        self.score = row[\"normalized_score\"]\n",
    "        self.dataset = row[\"source\"]\n",
    "    \n",
    "    def __str__(self) -> str:\n",
    "        string = \"Sentence Pair: {}\\n\".format(self.sentence_pair)\n",
    "        string += \"Score: {}\\t Dataset: {}\\n\".format(self.score,self.dataset)\n",
    "        return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeIrrelevantQuestions(df:pd.DataFrame):\n",
    "    return df[~ df.question.isin([\"Why?\",\"Explain your reasoning.\",\"Why not?\",\"Why did it happen?\",])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_semeval_df = pd.read_excel(\"datasets/semeval.xlsx\")\n",
    "\n",
    "test_semeval_df = pd.read_excel(\"datasets/test/semeval_unseen_domains.xlsx\")\n",
    "dev_semeval_df1 = pd.read_excel(\"datasets/develop/semeval_unseen_answers.xlsx\")\n",
    "dev_semeval_df2 = pd.read_excel(\"datasets/develop/semeval_unseen_questions.xlsx\")\n",
    "\n",
    "train_semeval_df = removeIrrelevantQuestions(train_semeval_df)\n",
    "test_semeval_df = removeIrrelevantQuestions(test_semeval_df)\n",
    "dev_semeval_df1 = removeIrrelevantQuestions(dev_semeval_df1)\n",
    "dev_semeval_df2 = removeIrrelevantQuestions(dev_semeval_df2)\n",
    "\n",
    "train_semeval_dataset = train_semeval_df.apply(QnliData, axis=1).to_numpy()\n",
    "test_semeval_dataset = test_semeval_df.apply(QnliData, axis=1).tolist()\n",
    "dev_semeval_dataset = np.append(\n",
    "    dev_semeval_df1.apply(QnliData, axis=1).to_numpy()\n",
    "    , dev_semeval_df2.apply(QnliData, axis=1).to_numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sag_df = pd.read_excel(\"datasets/sag.xlsx\")\n",
    "misc_df = pd.read_excel(\"datasets/misc.xlsx\")\n",
    "\n",
    "sag_dataset = sag_df.apply(QnliData, axis=1).tolist()\n",
    "misc_dataset = misc_df.apply(QnliData, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 16\n",
    "num_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9542 2711 5104\n",
      "Sentence Pair: ('Look at the schematic diagram. What will happen to the other 2 bulbs if the middle bulb burns out?', 'They will stay lit.')\n",
      "Score: 1.0\t Dataset: semeval\n",
      "\n",
      "9542 2711 5104\n",
      "Sentence Pair: ('Under what circumstances will a switch affect a bulb?', 'when the switch is connected between the bulb and the battery')\n",
      "Score: 0.5\t Dataset: semeval\n",
      "\n",
      "9542 2711 5104\n",
      "Sentence Pair: ('Why do both bulbs A and B stay on when bulb C is burned out?', 'If bulb C is damaged, there is still a closed path with the battery.')\n",
      "Score: 1.0\t Dataset: semeval\n",
      "\n",
      "9543 2710 5104\n",
      "Sentence Pair: ('Design a way to use carbon printing to find out if 2 Labrador retrievers have the same paw patterns. How will you know if the 2 dogs have paw patterns that are the same?', 'By comparing the 2 prints.')\n",
      "Score: 0.5\t Dataset: semeval\n",
      "\n",
      "9543 2710 5104\n",
      "Sentence Pair: ('Mary told her friend Sharice that she had a rug to sell. Sharice asked if the rug would fit perfectly, wall to wall, in her bedroom. Mary went home and measured the rug. She put her feet heel-to-toe and counted the number of shoe lengths it took to measure the rug. She found the rug was 18 shoes long and 12 shoes wide. Sharice did the same thing in her room to measure the space for the rug. Her floor was 18 shoes long and 12 shoes wide. A perfect fit! Sharice bought the rug and took it home. To her dismay, she found it was too short and too narrow for her bedroom! What could Mary and Sharice do to better measure the size of the rug?', 'They should return it and get another rug and measure with a meter tape.')\n",
      "Score: 1.0\t Dataset: semeval\n",
      "\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "for fold, (sag_index, misc_index) in enumerate(\n",
    "    zip(kf.split(sag_dataset), kf.split(misc_dataset))\n",
    "):\n",
    "    np.random.shuffle(train_semeval_dataset)\n",
    "    np.random.shuffle(test_semeval_dataset)\n",
    "    np.random.shuffle(dev_semeval_dataset)\n",
    "\n",
    "    train_test_sag_index, dev_sag_index = sag_index\n",
    "    train_test_misc_index, dev_misc_index = misc_index\n",
    "\n",
    "    train_sag_index, test_sag_index = train_test_split(\n",
    "        train_test_sag_index, test_size=0.25\n",
    "    )\n",
    "    train_misc_index, test_misc_index = train_test_split(\n",
    "        train_test_misc_index, test_size=0.25\n",
    "    )\n",
    "\n",
    "    train_datasets_list = [\n",
    "        train_semeval_dataset,\n",
    "        np.take(sag_dataset, train_sag_index),\n",
    "        np.take(misc_dataset, train_misc_index),\n",
    "    ]\n",
    "\n",
    "    dev_datasets_list = [\n",
    "        dev_semeval_dataset,\n",
    "        np.take(sag_dataset, dev_sag_index),\n",
    "        np.take(misc_dataset, dev_misc_index),\n",
    "    ]\n",
    "\n",
    "    test_datasets_list = [\n",
    "        test_semeval_dataset,\n",
    "        np.take(sag_dataset, test_sag_index),\n",
    "        np.take(misc_dataset, test_misc_index),\n",
    "    ]\n",
    "\n",
    "    train_dataset = torch.utils.data.ConcatDataset(train_datasets_list)\n",
    "    dev_dataset = torch.utils.data.ConcatDataset(dev_datasets_list)\n",
    "    test_dataset = torch.utils.data.ConcatDataset(test_datasets_list)\n",
    "\n",
    "    model = CrossEncoder(\"cross-encoder/qnli-electra-base\")\n",
    "    model_save_path = f'output/training_qnli_fold{fold}'+datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=train_batch_size,\n",
    "        shuffle=True,\n",
    "    )\n",
    "\n",
    "    evaluator = CECustomEvaluator.from_input_examples(dev_dataset, name=\"sts-dev\")\n",
    "\n",
    "    warmup_steps = math.ceil(\n",
    "        len(train_dataloader) * num_epochs * 0.1\n",
    "    )  # 10% of train data for warm-up\n",
    "\n",
    "    model.fit(\n",
    "        train_dataloader=train_dataloader,\n",
    "        freeze=True,\n",
    "        evaluator=evaluator,\n",
    "        epochs=num_epochs,\n",
    "        evaluation_steps=600,\n",
    "        warmup_steps=warmup_steps,\n",
    "        output_path=model_save_path,\n",
    "    )\n",
    "\n",
    "    test_evaluator = CECustomEvaluator.from_input_examples(\n",
    "        test_dataset, name=\"sts-test\"\n",
    "    )\n",
    "    test_evaluator(model, output_path=model_save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
